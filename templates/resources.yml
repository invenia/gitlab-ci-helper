---
# This file is machine-generated by `compile-resources`
variables:
  __GCH_TYPE_julia_ci: "script"
  __GCH_FILENAME_julia_ci: "julia-ci"
  __GCH_CONTENT_julia_ci: |
    #!/bin/bash

    # Automates the process of downloading a Julia binary and installing it. For use with Gitlab-CI.

    # Details on GitLab-CI environmental variables
    # http://docs.gitlab.com/ce/ci/variables/README.html

    set -e

    JULIA_CMD="julia --color=yes"

    if [ -n "$$JULIA_CI_DEPWARN" ]; then
        JULIA_CMD="$$JULIA_CMD --depwarn=$$JULIA_CI_DEPWARN"
    fi

    abspath() {
        echo "$$(cd "$$(dirname "$$1")"; pwd -P)/$$(basename "$$1")"
    }

    # Equivalent to `readlink -f` but works on macOS
    _readlink() {
        local file="$$1"

        # Iterate down a (possible) chain of symlinks
        while [ -L "$$file" ]; do
            file="$$(readlink $$file)"
        done

        echo $$(abspath "$$file")
    }

    # Checks whether the current environment is on CI and if not, throw an error. This
    # provides a safeguard against performing potentially unsafe operations locally. Any
    # function that should not be run locally should call this function at the top.
    ensure_ci() {
        if [ "$$CI" != "true" ]; then
            echo "Script is not being run within a CI environment" >&2
            exit 3
        fi
    }

    install_system_packages() {
        if [ -x "$$(command -v tar)" ] || [ -x "$$(command -v git)" ] || [ -x "$$(command -v curl)" ] || [ -x "$$(command -v rsync)" ]; then
            if [ -x "$$(command -v yum)" ]; then
                yum install -y -q git tar curl rsync
            elif [ -x "$$(command -v apt-get)" ]; then
                apt-get -y -q install git tar curl rsync
            else
                echo "Please ensure git, curl, rsync and tar are installed" >&2
                exit 1
            fi
        fi
    }

    git_clone() {
        # Note: The `--no-progress` flag disables only progress meters for all but "Checking out files"
        git clone "$$@" --no-progress 2>&1 | grep -v 'Checking out files'
    }

    # Based off of the logic in the travis build script:
    # https://github.com/travis-ci/travis-build/blob/master/lib/travis/build/script/julia.rb
    julia_url() {
        version=$$1; os=$$2; arch=$$3

        [ -z "$$os" ] && os=$$(uname)
        [ -z "$$arch" ] && arch=$$(uname -m)

        if [ "$$os" == "Linux" -a $$arch == "x86_64" ]; then
            os_arch="linux/x64"
            ext="linux-x86_64.tar.gz"
            nightly_ext="linux64.tar.gz"
        elif [ "$$os" == "Linux" -a $$arch == "i686" ]; then
            os_arch="linux/x86"
            ext="linux-i686.tar.gz"
            nightly_ext="linux32.tar.gz"
        elif [ "$$os" == "Linux" -a $$arch == "aarch64" ]; then
            os_arch="linux/aarch64"
            ext="linux-aarch64.tar.gz"
            nightly_ext="linuxaarch64.tar.gz"
        elif [ "$$os" == "Darwin" -a $$arch == "x86_64" ]; then
            os_arch="mac/x64"
            ext="mac64.dmg"
            nightly_ext="$$ext"
        elif [ "$$os" == "Darwin" -a $$arch == "arm64" ]; then
            # Julia on ARM only has tier 3 support and does not have builds for all versions
            # Pretend to be x86_64 and run with Rosetta for now
            # https://gitlab.invenia.ca/invenia/gitlab-ci-helper/-/issues/93
            os_arch="mac/x64"
            ext="mac64.dmg"
            nightly_ext="$$ext"
        elif [ "$$os" == "Windows" -a $$arch == "x86_64" ]; then
            os_arch="winnt/x64"
            ext="win64.exe"
            nightly_ext="$$ext"
        elif [ "$$os" == "Windows" -a $$arch == "i686" ]; then
            os_arch="winnt/x86"
            ext="win32.exe"
            nightly_ext="$$ext"
        else
            echo "Julia does not support $$arch $$os" >&2
            exit 1
        fi

        # Note: We are not supporting versions such as "release" or "1" as there isn't a nice URL for
        # this: https://github.com/travis-ci/travis-build/blob/master/lib/travis/build/script/julia.rb#L186
        if [[ "$$version" == "nightly" ]]; then
            url="julialangnightlies-s3.julialang.org/bin/$${os_arch}/julia-latest-$${nightly_ext}"
        elif [[ "$$version" =~ ^([0-9]+\.[0-9]+)\.[0-9]+$$ ]]; then
            url="julialang-s3.julialang.org/bin/$${os_arch}/$${BASH_REMATCH[1]}/julia-$${version}-$${ext}"
        elif [[ "$$version" =~ ^([0-9]+\.[0-9]+)$$ ]]; then
            url="julialang-s3.julialang.org/bin/$${os_arch}/$${version}/julia-$${version}-latest-$${ext}"
        else
            echo "Unknown Julia version: $${version}" >&2
            exit 1
        fi

        echo "https://$$url"
    }

    # Install Julia
    install_julia() {
        version=$$1; os=$$2; arch=$$3
        if [ -z "$$version" ]; then
            echo "A version is required" >&2
            exit 2
        fi
        [ -z "$$os" ] && os=$$(uname)

        url=$$(julia_url $$version $$os $$arch)

        # Change to the temporary directory so we don't mess up the CI_PROJECT_DIR
        mkdir -p "$$CI_TMP_DIR"
        pushd "$$CI_TMP_DIR" > /dev/null

        echo "Downloading: $$url"
        if [ "$$os" == "Linux" ]; then
            mkdir -p "$$JULIA_ROOT"
            curl -sSL --retry 7 "$$url" | tar -C "$$JULIA_ROOT" -x -z --strip-components=1 -f -
        elif [ "$$os" == "Darwin" ]; then
            curl -sSL -o julia.dmg "$$url"
            [ ! -d juliamnt ] && mkdir juliamnt
            hdiutil mount -readonly -mountpoint juliamnt julia.dmg
            cp -a juliamnt/*.app/Contents/Resources/julia "$$JULIA_ROOT"
            hdiutil detach juliamnt
            rm -rf juliamnt julia.dmg
        else
            echo "Unable to install in OS $$os" >&2
            exit 1
        fi

        # When provided pre-release version number (e.g "1.3-") make sure that the version of Julia matches the same pre-release.
        # Note: `"$$version" == *-` means $$version ends with a dash.
        julia_ver=$$($$JULIA_CMD -e 'V = VERSION; print(V.major, ".", V.minor, Base.lowerbound(V) <= V < Base.thisminor(V) ? "-" : "")')
        if [[ "$$version" == *- && "$$version" != "$$julia_ver" ]]; then
            echo "Expected Julia pre-release \"$$version\" but found \"$$julia_ver\"" >&2
            exit 1
        fi

        $$JULIA_CMD -e "using InteractiveUtils; versioninfo()"

        popd > /dev/null
    }

    # Inject the GitLab CI token into the given URL
    inject_token() {
        URL="$$1"
        ensure_ci
        [ -z "$$CI_JOB_TOKEN" ] || URL=$${URL/#https:\/\//https:\/\/gitlab-ci-token:$$CI_JOB_TOKEN@}
        echo "$$URL"
    }

    # Install the Git credential helper
    # Note: We only install the credential helper using this logic on Docker runners. We expect
    # the credential helper is already setup on shell runners
    install_credential_helper() {
        ensure_ci

        local gitlab_host=gitlab.invenia.ca
        local embedded_helper="$$(dirname $$(_readlink $$0))/gitlab-ci-credential"
        local installed_helper="$$(git config --get credential.https://$${gitlab_host}.helper || true)"

        if [[ ! -x "$$embedded_helper" ]]; then
            echo "Unable to find gitlab-ci-credential in the same directory as julia-ci" >&2
            exit 1
        fi

        # When the contents of the embedded helper differ from the installed one we'll update
        # to use the embedded helper.
        if ! cmp --silent "$$embedded_helper" "$$installed_helper"; then
            local helper="$$HOME/gitlab-ci-credential"
            cp -p "$$embedded_helper" "$$helper"

            # Note: Julia uses LibGit2 which doesn't seem to be able to read the local configuration.
            git config --global credential.https://$${gitlab_host}.helper "$$helper"
        else
            echo "The git credential helper is already installed and up to date." >&2
        fi
    }

    # Validate the credential helper is working correctly. Additional credential helpers
    # installed alongside `gitlab-ci-credential` helper can interfere by storing ephemeral
    # credentials.
    #
    # Note: We can use `GIT_CONFIG_NOSYSTEM` to have `git` ignore the system config file
    # but unfortunately this will not work with Julia
    validate_credential_helper() {
        if [[ -n "$$CI_PROJECT_URL" && -n "$$CI_JOB_TOKEN" ]]; then
            num_helpers=$$((git config --get-regexp 'credential.*helper' || true) | wc -l | tr -d '[:space:]')
            token=$$(echo -e "protocol=https\nhost=gitlab.invenia.ca\nusername=gitlab-ci-token\n\n" | git credential fill | grep ^password | cut -d= -f2)

            if [[ "$$token" != "$$CI_JOB_TOKEN" || $$num_helpers -ne 1 ]]; then
                config=$$(git config --show-origin --get-regexp 'credential.*' || true)
                echo -n "ERROR: Detected invalid git configuration. Most likely you have additional git " >&2
                echo -n "credential helpers which are interfering with the gitlab-ci-credential " >&2
                echo -e "helper. Listing git credential config:\n$$config" >&2
                exit 1
            fi
        else
            echo "Skipping validation of credential helper since environment variables CI_PROJECT_URL and CI_JOB_TOKEN are not defined" >&2
        fi
    }

    # Initialize private METADATA repo
    install_private_registries() {
        REGISTRY_DIR="$$JULIA_DEPOT_PATH/registries"
        PRIVATE_REGISTRY_DIR="$$REGISTRY_DIR/Invenia"
        PRIVATE_REGISTRY_URL="https://gitlab.invenia.ca/invenia/PackageRegistry.git"

        [ -d "$$JULIA_DEPOT_PATH" ] || mkdir -p "$$JULIA_DEPOT_PATH"

        # Always start fresh in case one of the registries fails to download, which then
        # leaves it in an incomplete state that persists across builds
        [ -d "$$REGISTRY_DIR" ] && rm -rf "$$REGISTRY_DIR"

        # NOTE: Adding the private registry may fail to authenticate unless the credential
        # helper has installed first.
        JULIA_DEPOT_PATH="$$JULIA_DEPOT_PATH" $$JULIA_CMD -e "
            using Pkg
            if VERSION >= v\"1.1\"
                if VERSION >= v\"1.7.0-beta1\"
                    DEFAULT_REGISTRIES = Pkg.Registry.DEFAULT_REGISTRIES
                else
                    DEFAULT_REGISTRIES = Pkg.Types.DEFAULT_REGISTRIES
                end

                Pkg.Registry.add([
                    DEFAULT_REGISTRIES;
                    RegistrySpec(url=\"$$PRIVATE_REGISTRY_URL\")
                ])
            else
                Pkg.update()  # Add default registries (General)
                run(\`git clone \"$$PRIVATE_REGISTRY_URL\" \"$$PRIVATE_REGISTRY_DIR\"\`)
            end
        "
    }


    # Remove the Julia installation, packages, and other temporary files created during the installation
    # and/or testing process
    uninstall() {
        # julia 1.3 installs as readonly on the mac runner
        [ -d "$$JULIA_ROOT" ] && chmod -R +w "$$JULIA_ROOT"
        # some artifacts install as readonly on the mac runner
        # this is fixed in Julia 1.6, see https://github.com/JuliaPackaging/Yggdrasil/issues/1969
        [ -d "$$JULIA_DEPOT_PATH" ] && chmod -R +w "$$JULIA_DEPOT_PATH"
        rm -rf "$$JULIA_ROOT" "$$JULIA_DEPOT_PATH" "$$CI_TMP_DIR"
    }

    # Export the environmental variables. Needs to be run with "source ..." to work
    export_vars() {
        export PATH CI_TMP_DIR PKG_NAME JULIA_ROOT JULIA_DEPOT_PATH JULIA_PROJECT TMPDIR
    }

    # Export the environmental variables as strings, so the shell can eval them regardless of the shell
    # being used. e.g. `eval $$(./julia-ci echo-export)`
    echo_export_vars() {
        echo "export PATH=\"$$PATH\""
        echo "export CI_TMP_DIR=\"$$CI_TMP_DIR\""
        echo "export PKG_NAME=\"$$PKG_NAME\""
        echo "export JULIA_ROOT=\"$$JULIA_ROOT\""
        echo "export JULIA_DEPOT_PATH=\"$$JULIA_DEPOT_PATH\""
        echo "export JULIA_PROJECT=\"$$JULIA_PROJECT\""
        echo "export TMPDIR=\"$$TMPDIR\""
    }

    # Installs a custom version of Pkg.jl for debugging:
    # https://gitlab.invenia.ca/invenia/gitlab-ci-helper/issues/5
    pkg_debug_hack() {
        pushd "$$CI_TMP_DIR"
        [ -d "Pkg.jl" ] && rm -rf "Pkg.jl"
        echo "Cloning the debugging version of Pkg"
        git_clone https://github.com/invenia/Pkg.jl.git --branch cv/debugging
        # Don't start Julia in the current directory, since it will load the local Project
        # file and write to a local Manifest file, whereas we want to use the global Manifest
        popd > /dev/null
        JULIA_DEPOT_PATH="$$JULIA_DEPOT_PATH" $$JULIA_CMD -e "
            using Pkg
            Pkg.develop(PackageSpec(name=\"Pkg\",
                                    uuid=\"3e4c069f-8883-4506-90ba-d9dcc9d305b5\",
                                    path=joinpath(\"$$CI_TMP_DIR\", \"Pkg.jl\")))
        "
        # Ensure that Pkg is using the right now
        JULIA_DEPOT_PATH="$$JULIA_DEPOT_PATH" $$JULIA_CMD -e "
            using Pkg
            @show Base.PkgId(Pkg) # Check UUID
            Pkg.pkg\"status\"     # Check version
        "
    }

    # Install the project at the current directory as a Julia package
    install_this_package() {
        $$JULIA_CMD -e "
            using Pkg
            Pkg.develop(PackageSpec(url=pwd()))
            if VERSION >= v\"1.1.0-rc1\"
                Pkg.build(\"$$PKG_NAME\", verbose=true)
            else
                Pkg.build(\"$$PKG_NAME\")
            end
        "
    }

    # Run package tests
    run_tests() {
        if [[ -f "Project.toml" || -f "JuliaProject.toml" ]]; then
            # The Project file is used if present we can make an environment. Additionally,
            # using an environment allows the option of using a Manifest file which is ignored
            # when using "dev".
            $$JULIA_CMD --project --depwarn=$${JULIA_DEPWARN:-yes} -e "
                using Pkg
                if haskey(ENV, \"RETRY_ERRORS\")
                    check = (s, e) -> e isa Pkg.Types.PkgError && any(occursin.(split(ENV[\"RETRY_ERRORS\"], '\\n'), e.msg))
                    retry(Pkg.instantiate, check=check)()
                else
                    Pkg.instantiate()
                end
                isfile(\"Manifest.toml\") && Pkg.status()  # Display any branches being used in a Manifest.toml
                if VERSION >= v\"1.1.0-rc1\"
                    Pkg.build(verbose=true)
                else
                    Pkg.build()
                end
                Pkg.test(coverage=true)
            "
        else
            install_this_package
            $$JULIA_CMD -e --depwarn=$${JULIA_DEPWARN:-yes} "
                using Pkg
                Pkg.test(\"$$PKG_NAME\"; coverage=true)
            "
        fi
    }

    # Build package documentation using Documenter
    build_docs() {
        # Note: instantiate seems to skip building the developed package.
        # We'll trigger a full build if the package contains a build.jl
        $$JULIA_CMD --project=docs/ -e "
            using Pkg
            !isfile(\"docs/Project.toml\") && !isfile(\"docs/JuliaProject.toml\") && Pkg.add(\"Documenter\")
            Pkg.develop(PackageSpec(path=\".\"))
            if haskey(ENV, \"RETRY_ERRORS\")
                check = (s, e) -> e isa Pkg.Types.PkgError && any(occursin.(split(ENV[\"RETRY_ERRORS\"], '\\n'), e.msg))
                retry(Pkg.instantiate, check=check)()
            else
                Pkg.instantiate()
            end
            if isfile(\"deps/build.jl\")
                if VERSION >= v\"1.1.0-rc1\"
                    Pkg.build(verbose=true)
                else
                    Pkg.build()
                end
            end
        "
        $$JULIA_CMD --project=docs/ docs/make.jl

        if [ ! -d docs/build ]; then
            echo "Documentation was not built" >&2
            exit 1
        fi

        # Move the rendered documentation to a folder called "documentation" in the root of
        # the repo which will be saved in an artifact.
        mkdir documentation
        mv docs/build/* documentation/
    }

    # Save raw coverage files and an HTML report.
    gen_coverage() {
        ensure_ci
        COVERAGE_DIR="$$CI_PROJECT_DIR/coverage/$$CI_JOB_NAME"
        mkdir -p "$$COVERAGE_DIR/html"
        $$JULIA_CMD --depwarn=no -e "
            using Pkg
            Pkg.add(\"Coverage\")
            "
        $$JULIA_CMD -e "
            using Printf
            cd(\"$$CI_PROJECT_DIR\")
            using Coverage
            cov = process_folder()
            c, t = get_summary(cov)
            @printf(\"Test Coverage %.2f%%\\n\", t == 0 ? 0 : c/t * 100)
            LCOV.writefile(\"$$COVERAGE_DIR/coverage.info\", cov)
        "
        if [ -x "$$(command -v genhtml)" ]; then
            genhtml --version
            cp -r "$$CI_PROJECT_DIR/src" "$$COVERAGE_DIR/html/"

            # No coverage files will result in: `ERROR: no valid records found in tracefile`
            if [ -n "$$(find "$$CI_PROJECT_DIR/src" -name '*.cov')" ]; then
                genhtml -o "$$COVERAGE_DIR/html" --prefix "$$CI_PROJECT_DIR" "$$COVERAGE_DIR/coverage.info"
            else
                echo "WARNING: Unable to generate coverage report as no coverage files are present." >&2
            fi

            find "$$COVERAGE_DIR/html" -type f -name "*.jl" -delete
        else
            echo "lcov is not installed: can't generate coverage report." >&2
        fi
        # Copy over all the coverage files while still maintaining the directory structure.
        rsync -r --include='*.cov' --include '*.mem' --include='*/' --exclude='*' "$$CI_PROJECT_DIR/src/" "$$COVERAGE_DIR/raw"
    }

    publish_coverage() {
        ensure_ci
        coverage_dir=$$1

        genhtml --version
        mkdir -p "$$coverage_dir"
        cp -r "$$CI_PROJECT_DIR/src" "$$coverage_dir"

        # Store the trace file paths in an array.
        # Note: special care is taken to handle spaces in paths (https://stackoverflow.com/a/32931403)
        trace_files=()
        while IFS= read -r line; do
            trace_files+=( "$$line" )
        done < <(find "$$CI_PROJECT_DIR" -type f -name coverage.info)

        # Display combined summary of the trace files (`lcov --directory src -o -a "merged.info" file1 -a file2 ...`)
        # Save combined coverage to `merged.info`
        printf '\-a "%s"\n' "$${trace_files[@]}" | xargs lcov --directory src -o "$$coverage_dir/merged.info"

        echo "Test Coverage $$(genhtml -o "$$coverage_dir" --no-prefix "$$coverage_dir/merged.info" 2>&1 | grep lines | awk '{print $$2}')"
        find "$$coverage_dir" -type f -name "*.jl" -delete

        # Convert output to cobertura for line coverage visualization on Gitlab PRs
        lcov_cobertura "$$coverage_dir/merged.info" -o "$$coverage_dir/cobertura.xml"
    }

    format() {
        $$JULIA_CMD -e 'using Pkg; Pkg.add("JuliaFormatter")'
        # This git commmand specifically is needed to find changed files
        # see https://forum.gitlab.com/t/ci-cd-pipeline-get-list-of-changed-files/26847/18
        CHANGED_FILES=$$(git diff-tree --no-commit-id --name-only -r $$CI_MERGE_REQUEST_TARGET_BRANCH_SHA -r $$CI_COMMIT_SHA)
        # grep errors when no matches are found, using "||" prevents that error from failing the CI job
        CHANGED_JULIA_FILES=$$(echo "$$CHANGED_FILES" | grep '\.jl$$' || echo "")
        $$JULIA_CMD -e 'using JuliaFormatter; format(ARGS, BlueStyle(); verbose=true, overwrite=true)' $$CHANGED_JULIA_FILES
        export BAD_FORMAT_FILES=$$(git --no-pager diff --name-only -r $$CI_COMMIT_SHA)
        # Print all the files the formatter changed
        for f in $$(echo "$$BAD_FORMAT_FILES" | xargs); do
            git --no-pager diff -r $$CI_COMMIT_SHA $$f
        done
        if [[ $$(echo "$$BAD_FORMAT_FILES" | wc -c) > 1 ]]; then
            echo "These files aren't formatted properly:"
            echo "$$BAD_FORMAT_FILES"
            exit 1
        else
            echo "No formatting issues found"
        fi
    }

    cmd=$$1; shift;
    if [ -z "$$cmd" ]; then
        echo "A command is required" >&2
        exit 2
    fi

    if [ -z "$$CI_PROJECT_DIR" ]; then
        if [ -z "$$CI_TMP_DIR" ]; then                 # Allow custom specification of a temp dir
            if [ $$(uname) == "Linux" ]; then
                SHACMD=sha1sum
            else
                SHACMD=shasum
            fi
            _TMP_DIR="$${TMPDIR:-$${TMP:-$${TEMP:-$${TEMPDIR:-/tmp}}}}" # Get the system's temp directory
            SHA=$$(pwd | $$SHACMD | cut -d' ' -f1)         # take the SHA of the current directory
            CI_TMP_DIR="$$_TMP_DIR/$$SHA"                  # and use it to make a temp directory
            [ -d "$$CI_TMP_DIR" ] || mkdir "$$CI_TMP_DIR"  # if it doesn't already exist
        fi
        PKG_NAME=$$(basename $${PWD/%.jl/})             # Assume the current directory is the cloned package
    else
        CI_TMP_DIR="$${CI_PROJECT_DIR}.tmp"            # Temporary directory already created by GitLab
        PKG_NAME=$$(basename $${CI_PROJECT_DIR/%.jl/})  # Name of the Julia package we are testing
    fi

    JULIA_ROOT="$$CI_TMP_DIR/julia"                # Julia installation directory
    JULIA_DEPOT_PATH="$$CI_TMP_DIR/depot"          # Pkg3 package depot
    JULIA_PROJECT="@."                            # Location specifier for projects with Project.toml files
    METADATA_BRANCH="invenia"                     # Branch name to use for the custom invenia/METADATA.jl repo

    # Work around (hopefully) https://github.com/JuliaLang/Pkg.jl/issues/795 by ensuring that
    # package files that are downloaded and extracted are on the same volume as their destination
    # after being moved
    TMPDIR="$$CI_TMP_DIR"

    # Add JULIA_ROOT to PATH if it hasn't been added yet
    if [[ ":$$PATH:" != *":$$JULIA_ROOT/bin:"* ]]; then
        PATH="$${JULIA_ROOT}/bin:$${PATH}"
    fi

    if [ "$$cmd" == "install" ]; then
        uninstall  # Allows re-runs to work
        [ "$$CI_DISPOSABLE_ENVIRONMENT" == "true" ] && install_system_packages
        if [ "$$CI" == "true" ]; then
            install_credential_helper
            validate_credential_helper
        fi
        install_julia $$@
        install_private_registries
    elif [ "$$cmd" == "install-julia" ]; then
        install_julia $$@
    elif [ "$$cmd" == "install-package" ]; then
        install_this_package
    elif [ "$$cmd" == "check-prerequisites" ]; then
        install_system_packages
    elif [ "$$cmd" == "install-cred-helper" ]; then
        install_credential_helper
        validate_credential_helper
    elif [ "$$cmd" == "install-pkg-hack" ]; then
        pkg_debug_hack
    elif [ "$$cmd" == "export" ]; then
        export_vars
    elif [ "$$cmd" == "echo-export" ]; then
        echo_export_vars
    elif [ "$$cmd" == "clean" ]; then
        uninstall
    elif [ "$$cmd" == "coverage" ]; then
        gen_coverage
    elif [ "$$cmd" == "publish-coverage" ]; then
        publish_coverage $$@
    elif [ "$$cmd" == "format" ]; then
        format
    elif [ "$$cmd" == "test" ]; then
        run_tests
    elif [ "$$cmd" == "build-docs" ]; then
        build_docs
    elif [ "$$cmd" == "publish-docs" ]; then
        echo "Executing \`julia-ci publish-docs\` is deprecated and it's functionality has been included in \`julia-ci build-docs\`." >&2

        # Only re-build documentation if it hasn't already been built by a previous `julia-ci build-docs`
        if [ ! -d documentation ]; then
            build_docs
        fi
    else
        echo "Command not recognized" >&2
        exit 2
    fi
  __GCH_TYPE_gitlab_ci_credential: "script"
  __GCH_FILENAME_gitlab_ci_credential: "gitlab-ci-credential"
  __GCH_CONTENT_gitlab_ci_credential: |
    #!/bin/bash

    # A custom git credential helper which works with GitLab CI. Can be installed by adding the
    # following to a git configuration file:
    #
    # ```bash
    # HOSTNAME=...
    # git config --global credential.https://$$HOSTNAME.helper "$$HOME/gitlab-ci-credential"
    # ```
    #
    # You can test the behaviour of this script by running the following and entering key/value
    # pairs or just pressing enter twice:
    #
    # ```bash
    # CI_PROJECT_URL=https://$$HOSTNAME CI_JOB_TOKEN=passwd ./gitlab-ci-credential get
    # ```
    #
    # If you which to use test the script with your credentials you can do do by providing your
    # personal access token via an environmental variable:
    #
    # ````bash
    # export CI_PROJECT_URL=https://$$HOSTNAME CI_JOB_TOKEN=personal-access-token
    # ```

    # https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage#_a_custom_credential_cache

    # Note: both CI_PROJECT_URL and CI_JOB_TOKEN are defined automatically when running inside
    # of the GitLab CI (https://docs.gitlab.com/ee/ci/variables/#predefined-variables-environment-variables)
    CI_HOST=$$(echo "$$CI_PROJECT_URL" | sed -e 's!.*://\([^/]*\).*!\1!')
    CI_USER="gitlab-ci-token"

    matched=1
    IFS='='
    while read -r line; do
        [ "$$line" == "" ] && break

        if [ "$$matched" -eq 1 ]; then
            p=($$line)
            key=$${p[0]}
            val=$${p[1]}
            if [ "$$key" == "protocol" -a "$$val" != "https" ]; then
                matched=0
            elif [ "$$key" == "host" -a "$$val" != "$$CI_HOST" ]; then
                matched=0
            elif [ "$$key" == "username" -a "$$val" != "$$CI_USER" ]; then
                matched=0
            fi
        fi
    done < /dev/stdin

    if [ "$$1" == "get" -a ! -z "$$CI_JOB_TOKEN" -a $$matched -eq 1 ]; then
        echo "protocol=https"
        echo "host=$${CI_HOST}"
        echo "username=$${CI_USER}"
        echo "password=$${CI_JOB_TOKEN}"
    fi
  __GCH_TYPE_common: "function"
  __GCH_CONTENT_common: |
    #!/bin/bash

    set -e  # Required to cause a job failure when any of these commands fail

    function echo_eval {
        local green='\033[32m'
        local reset='\033[0m'

        local cmd="$$@"
        echo -e "$${green}$$ $${cmd}$${reset}" >&2
        eval "$$cmd"
    }

    function handle_throttling {
        local cmd="$$@"

        local retries_left=3
        local wait=15
        while true; do
            (eval "$$cmd") && RC=$$? || RC=$$?

            # Note: Error code isn't specific to throttling and we may want to also
            # check against the output given by the command.
            if [ $$RC -eq 255 ] && [ $$retries_left -gt 0 ]; then
                echo "Command failed. Retrying in $$wait seconds..." >&2
                sleep $$wait
                retries_left=$$((retries_left - 1))
                wait=$$((wait * 2))
            else
                return $$RC
            fi
        done
    }

    function package_install {
        # Note: Expects the name of the package to contain an executable of the same name
        # which is installed on the path. If this assumption isn't invalid we'll attempt
        # to install the package each time this is ran
        refresh_pkgs
        for pkg in "$$@"; do
            if [[ ! -x "$$(command -v $$pkg)" ]]; then
                if [[ -x "$$(command -v yum)" ]]; then
                  echo_eval $${SUDO} yum -y install $$pkg
                elif [[ -x "$$(command -v apt-get)" ]]; then
                    echo_eval $${SUDO} apt-get -y install $$pkg
                elif [[ -x "$$(command -v brew)" ]]; then
                    echo_eval brew install $$pkg
                else
                    echo "Unsupported package manager" >&2
                    return 1
                fi
            else
                echo "$$pkg is already installed"
            fi
        done
    }

    function install_aurora_credentials {
        [[ $$INSTALLED_AURORA_CREDENTIALS == true ]] && return 0

        package_install jq
        install_cloudspy

        # Create the .pgpass file
        [ -z "$$PGPASSFILE" ] && export PGPASSFILE=$$(pwd)/.pgpass
        echo_eval touch $$PGPASSFILE
        echo_eval chmod u=rw,go= $$PGPASSFILE

        # Generate AURORA_* environmental variables and install password to PGPASSFILE
        AURORA_EIS_CREDENTIALS=$$(aws-eisdb-credentials $$@ --output json)

        export AURORA_READER_ENDPOINT=$$(jq -r .reader <<< $$AURORA_EIS_CREDENTIALS)
        export AURORA_DATABASE=$$(jq -r .dbname <<< $$AURORA_EIS_CREDENTIALS)
        export AURORA_USER=$$(jq -r .username <<< $$AURORA_EIS_CREDENTIALS)
        export AURORA_PORT=$$(jq -r .port <<< $$AURORA_EIS_CREDENTIALS)

        INSTALLED_AURORA_CREDENTIALS=true
    }

    [[ $$CI_DISPOSABLE_ENVIRONMENT == "true" ]] && SUDO="" || SUDO="sudo"

    function refresh_pkgs() {
        [[ $$REFRESHED_PKGS == true ]] && return 0

        if [[ -x "$$(command -v apt-get)" ]]; then
            echo_eval $${SUDO} apt-get update
        elif [[ -x "$$(command -v brew)" ]]; then
            echo_eval brew update
        fi

        REFRESHED_PKGS=true
    }

    function install_python() {
        [[ $$INSTALLED_PYTHON == true ]] && return 0

        # Don't re-install Python 3 if it already exists as this might run in a python docker image where
        # the specific version of 3 that we want is already installed.
        # When Python 3 is already installed ensure that venv is also correctly installed.
        local tmp=$$(mktemp -dt venv.XXXXXXXX)
        if ! [[ -x "$$(command -v python3)" ]] || ! (python3 -m venv $$tmp > /dev/null && rm -rf $$tmp); then
            refresh_pkgs
            if [[ -x "$$(command -v yum)" ]]; then
                echo_eval $${SUDO} yum -y -d1 install python3
            elif [[ -x "$$(command -v apt-get)" ]]; then
                echo_eval $${SUDO} apt-get -y install python3 python3-venv
            fi
        fi

        # Ignore built-in python3 on Mac
        if [[ "$$(command -v brew)" ]]; then
            refresh_pkgs
            if [[ "$$(command -v python3)" == "/usr/bin/python3" ]]; then
                echo_eval "(brew install python && brew link --overwrite python) || (brew upgrade python && brew cleanup python)"
            fi
        fi

        # enter_python_venv calls this function so we need to set the flag early so we don't end
        # up in an infinite loop
        INSTALLED_PYTHON=true

        # Always enter a virtualenv to ensure we can just call `python` and `pip` and use Python 3
        enter_python_venv
    }

    function install_awscli() {
        [[ $$INSTALLED_AWSCLI == true ]] && return 0

        # PyYAML requires gcc
        if ! [[ -x "$$(command -v gcc)" ]]; then
            refresh_pkgs
            if [[ -x "$$(command -v yum)" ]]; then
                echo_eval $${SUDO} yum -y -d1 install gcc
            elif [[ -x "$$(command -v apt-get)" ]]; then
                echo_eval $${SUDO} apt-get -y install gcc
            elif [[ -x "$$(command -v brew)" ]]; then
                echo_eval brew install gcc
            fi
        fi

        install_python

        echo_eval python3 -m pip install --upgrade awscli
        echo_eval aws --version  # Note: Also displays the Python version

        INSTALLED_AWSCLI=true
    }

    function install_python_dev(){
        refresh_pkgs
        install_python

        # Check if dev python is already installed
        # Prevents older versions from overwriting manually installed python on some docker images
        check_py="from distutils import sysconfig as s; dir = s.get_python_inc(); from os.path import isfile; import sys; sys.exit(not isfile(dir + '/Python.h'))"
        python3 -c "$$check_py" 2>/dev/null && return 0

        if [[ -x "$$(command -v yum)" ]]; then
            echo_eval $${SUDO} yum -y -d1 install gcc python3-devel
        elif [[ -x "$$(command -v apt-get)" ]]; then
            echo_eval $${SUDO} apt-get -y install python3-dev
        fi
    }

    function install_cloudspy() {
        [[ $$INSTALLED_CLOUDSPY == true ]] && return 0

        install_python_dev

        if [[ -x "$$(command -v yum)" ]]; then
            echo_eval $${SUDO} yum -y -d1 install git
        elif [[ -x "$$(command -v apt-get)" ]]; then
            echo_eval $${SUDO} apt-get -y install git
        fi

        install_private_pypi_creds

        # Optionally disable binary install
        opt=""
        [[ "$$NO_BINARY" == "true" ]] && opt="--no-binary :all:"
        echo_eval python3 -m pip install --upgrade cloudspy $$opt

        # Needs to be defined here for the ".deploy" jobs
        echo_eval export AWS_SHARED_CREDENTIALS_FILE="$$(pwd)/aws-creds-$${CI_PIPELINE_ID}"

        # Retain any user specified credentials in the new file. Needed on macOS runners.
        if [ -f ~/.aws/credentials ]; then
            echo_eval cp ~/.aws/credentials $$AWS_SHARED_CREDENTIALS_FILE
        fi

        # Specify a custom configuration file for using cloudspy as an AWS CLI plugin
        echo_eval export AWS_CONFIG_FILE="$$(pwd)/aws-config-$${CI_PIPELINE_ID}"

        # Retain any user specified config in the new file. Needed on macOS runners.
        if [ -f ~/.aws/config ]; then
            echo_eval cp ~/.aws/config $$AWS_CONFIG_FILE
        fi

        cloudspy configure --auto-skip  # Skip installation of alias file

        INSTALLED_CLOUDSPY=true
    }

    function stack_name() {
        # replaces all characters that aren't alphanumerics or newlines with `-`
        local prefix=$$(echo $$1 | tr -sc '[:alnum:]\n' '-')
        # Limit characters (stackname + -TestRole, must be <= 64 characters)
        local character_limit=$${2:-55} # Default is 55
        local hash_size=$${3:-0} # Default is 0
        local stackname=""

        if [ -z "$$prefix" ]; then
            echo 'A stack prefix must be provided to `stack_name`' >&2
            return 1
        fi

        # Make unique stacks for each executed pipeline for the default branch. This will allow fast successive merges
        # to work correctly.
        if [[ $${CI_COMMIT_REF_SLUG} == $${CI_DEFAULT_BRANCH} ]]; then
            stackname="$${prefix}-$${CI_DEFAULT_BRANCH}-$${CI_PIPELINE_ID}"
        else
            stackname="$${prefix}-$${CI_COMMIT_REF_SLUG//\//-}"  # Replace any forward slashes with a hyphen
        fi

        local hash_string=""
        if [[ "$$hash_size" > 0 ]]; then
            hash_string="-$$(echo -n $$stackname | sha256sum | cut -c1-$$hash_size)"
            character_limit=$$((character_limit-(hash_size+1)))
        fi

        stackname="$${stackname:0:character_limit}"
        stackname="$${stackname%-}" # Remove ending hyphen if it exists
        echo $$stackname$$hash_string
    }

    function stack_status() {
        local stack_name=$$1
        local status

        install_awscli >&2

        # Note: Rather slow as this lists information for all activate/deleted stacks and filters locally
        # Note: Cannot use `--output text` as there seems to be a bug where multiple "None" values are given even though we ask for only a single status
        status=$$(handle_throttling 'aws cloudformation list-stacks --query "reverse(sort_by(StackSummaries[?StackName==\`'$$stack_name'\`],&CreationTime))[0].StackStatus" --output json')

        if [[ "$$status" != null ]]; then
            echo $$status | sed 's/"//g'
        else
            echo "Unable to retrieve stack status for stack name $$stack_name"
            return 1
        fi
    }

    function stack_exists() {
        local stack_name=$$1
        local error

        install_awscli >&2

        error=$$(aws cloudformation describe-stacks --stack-name $$stack_name 2>&1 >/dev/null)

        if [[ -z "$$error" ]]; then
            return 0
        elif [[ "$$error" =~ "Stack with id $$stack_name does not exist" ]]; then
            return 1
        else
            echo "$$error" >&2
            return 2
        fi
    }

    function aws_account_id() {
        if [[ ! -x "$$(command -v aws)" ]] && [[ -x "$$(command -v curl)" ]] && curl -s --max-time 2 http://169.254.169.254 &> /dev/null; then
            curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | grep -oP '(?<="accountId" : ")[^"]*(?=")'
        else
            install_awscli >&2
            aws sts get-caller-identity --query Account --output text
        fi
    }

    function aws_region() {
        if [[ -x "$$(command -v curl)" ]] && curl -s --max-time 2 http://169.254.169.254 &> /dev/null; then
            curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | grep -oP '(?<="region" : ")[^"]*(?=")'
        else
            install_awscli >&2
            # This will return "" if a region is not specified in the config
            aws configure get region
        fi
    }

    function assume_test_role() {
        local role
        if [[ -n "$$1" && ! "$$1" =~ ^-- ]]; then
            role=$$1
            shift
        fi

        if [[ "$$role" =~ ^arn: ]]; then
            role=$$role
        elif [[ -n "$$role" && ! "$$role" =~ ^arn ]]; then
            role="arn:aws:iam::$$(aws_account_id):role/$${role}"
        elif [[ -z "$$role" && -n "$$STACK_NAME" ]]; then
            role="arn:aws:iam::$$(aws_account_id):role/$${STACK_NAME}-TestRole"
        else
            echo 'Either a test role or STACK_NAME must be specified' >&2
            return 1
        fi

        install_cloudspy

        echo_eval aws-credentials \
          --credentials-file $$AWS_SHARED_CREDENTIALS_FILE \
          --role-arn $$role \
          --role-session-name "test-$${CI_PIPELINE_ID}" \
          $$@
        export AWS_PROFILE="test-$${CI_PIPELINE_ID}"
    }

    function unassume_test_role() {
        if [[ $$AWS_PROFILE == "test-$${CI_PIPELINE_ID}" ]]; then
            unset AWS_PROFILE
        fi
    }

    function within_venv() {
        install_python

        # https://stackoverflow.com/a/42580137
        python3 -c 'import sys; sys.exit(0) if hasattr(sys, "real_prefix") or (hasattr(sys, "base_prefix") and sys.base_prefix != sys.prefix) else sys.exit(1)'
    }

    # Create a python 3 virtual env and make sure pip is at the latest version
    # You will need to deactivate the venv yourself
    #
    # Arguments:
    # $$1: venv name [Optional]
    function enter_python_venv {
        # We need python to be installed before running this
        install_python

        local venv=$${1:-venv}

        if within_venv; then
            # Note: Only macOS doesn't have realpath installed by default
            if ! [[ -x "$$(command -v realpath)" ]]; then
                refresh_pkgs
                if [[ -x "$$(command -v yum)" ]]; then
                    echo_eval $${SUDO} yum -y -d1 install coreutils
                elif [[ -x "$$(command -v apt-get)" ]]; then
                    echo_eval $${SUDO} apt-get -y install coreutils
                elif [[ -x "$$(command -v brew)" ]]; then
                    echo_eval brew install coreutils
                fi
            fi

            # When a venv name is not specified we only care that we reside in a venv
            if [[ -z "$$1" ]]; then
                return

            # If the VIRTUAL_ENV matches the specified venv we are already within the right venv
            elif [[ -n "$$VIRTUAL_ENV" && "$$(realpath $$VIRTUAL_ENV)" == "$$(realpath $$(pwd)/$${venv})" ]]; then
                return

            # Deactivate if we are in another venv
            elif [[ -n "$$VIRTUAL_ENV" ]]; then
                echo_eval deactivate
            fi
        fi

        # If there is already a virtualenv with that name, activate it and exit
        if [[ -d ./$$venv ]] ; then
            # Activate the one we want
            echo_eval source ./$${venv}/bin/activate
        else
            # Create and activate the venv we want
            echo_eval python3 -m venv $$venv
            echo_eval source ./$${venv}/bin/activate
            echo_eval python3 -m pip install --index-url https://pypi.org/simple --upgrade pip wheel
        fi
    }

    function install_private_pypi_creds {
        [[ $$INSTALLED_PRIVATE_PYPI_CREDS == true ]] && return 0

        # We don't need python installed here specifically, but we might as well
        install_python

        # The private pypi credentials exist as CI Variables CI_PYPI_USERNAME and CI_PYPI_PASSWORD

        # Write the .pip config file
        PIPCONF=$$HOME/.pip
        mkdir -p $$PIPCONF
        echo "Creating: $$PIPCONF/pip.conf"
        cat >$$PIPCONF/pip.conf <<EOL
    [global]
    index-url = https://$$CI_PYPI_USERNAME:$$CI_PYPI_PASSWORD@gitlab.invenia.ca/api/v4/projects/501/packages/pypi/simple/
    extra-index-url = https://pypi.org/simple/
    EOL

        # Write the .pypirc config file
        echo "Creating: $$HOME/.pypirc"
        cat >$$HOME/.pypirc <<EOL
    [distutils]
    index-servers = gitlab

    [gitlab]
    repository: https://gitlab.invenia.ca/api/v4/projects/501/packages/pypi/
    username: $$CI_PYPI_USERNAME
    password: $$CI_PYPI_PASSWORD
    EOL

        INSTALLED_PRIVATE_PYPI_CREDS=true
    }

    function docker_image_cp {
        local image=$$1
        local source=$$2  # Path from within image
        local dest=$$3    # Path on local system

        local container_id=$$(docker create $${image})

        # Note: `() && rc=$$? || rc=$$?` allows the subshell to always succeed and record the return code
        local rc
        (docker cp $${container_id}:$${source} $${dest}) && rc=$$? || rc=$$?

        docker rm $${container_id}
        return $$rc
    }

    function rescale_json_values {
        local filename=$$1
        local time_unit=$$2
        local mem_unit=$$3
        local alloc_unit=$$4

        if [ -z "$$filename" ]; then
            echo 'A benchmark filename must be provided' >&2
            return 1
        fi

        if [ -z "$$time_unit" ]; then
            time_unit=ns
        fi

        if [ -z "$$mem_unit" ]; then
            mem_unit=b
        fi

        jq --sort-keys \
            --arg time_unit $$time_unit \
            --arg mem_unit $$mem_unit \
            --arg alloc_unit "$$alloc_unit" \
            --argjson units '{
                "time": {"ns": 1, "us": 1e3, "ms": 1e6, "s": 1e9, "m": 6e10, "h": 3.6e12},
                "memory": {"b": 0, "KiB": 1, "MiB": 2, "GiB": 3},
                "allocs": {"": 0, "K": 3, "M": 6, "G": 9, "T": 12}
            }' \
            'with_entries(
                if (.key | endswith("time")) then {key: (.key + "(" + $$time_unit + ")"), value: (.value / $$units.time[$$time_unit] | . * 100 | floor | . / 100)}
                elif (.key | endswith("memory")) then {key: (.key + "(" + $$mem_unit + ")"), value: ((.value / pow(1024; $$units.memory[$$mem_unit])) | . * 100 | floor | . / 100)}
                elif (.key | endswith("allocs")) then {key: (.key + "(" + $$alloc_unit + ")"), value: ((.value / pow(10; $$units.allocs[$$alloc_unit])) | . * 100 | floor | . / 100)}
                else .
                end
            )' $$filename
    }

    function format_benchmark_reports {
        local filename=$$1
        local source_name=$$2
        local nesting_level=$$3
        local save_path=$$4

        if [ -z "$$filename" ]; then
            echo 'A benchmark filename must be provided' >&2
            return 1
        fi

        if [ -z "$$source_name" ]; then
            source_name=metrics
        fi

        exclude="^$$"
        if [ -n "$$nesting_level" ]; then
            exclude="([|].*?){$$nesting_level,}"
        fi

        if [ -z "$$save_path" ]; then
            save_path=$$(dirname $$filename)
        fi

        # Filter values if needed
        filtered=$$(jq --arg regexp $$exclude 'with_entries(select(.key | test($$regexp)| not))' $$filename)

        # Add quotes to ensure keys with spaces don't get cut off
        echo $$filtered | jq -r --arg source $$source_name 'to_entries[] | "\"\($$source) | \(.key)\" \(.value)"' > $$save_path/metrics.txt
        # Remove gc times from fancy comparison widget
        echo $$filtered | jq --arg source $$source_name '
            with_entries(select(.key | test(".*gctime.{0,4}")| not)) |
            [ { subject: $$source, metrics: [ to_entries[] | { name: .key,  value, "desiredSize": "smaller" } ] } ]
        ' > $$save_path/performance.json
    }

    function validate_tag {
        local tag=$$1
        # # A semantic version which contains an optional pre-release component (https://semver.org/spec/v2.0.0.html)
        # Note: we don't start our version numbers with `v` like Julia packages do.
        if [[ ! $$tag =~ ^[0-9]+\.[0-9]+\.[0-9]+(\-[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*)?(\+[0-9A-Za-z-]+(\.[0-9A-Za-z-]+)*)?$$ ]]; then
            echo "Invalid tag format given for $$tag" >&2
            return 1
        fi
    }

    function get_major_version {
        local tag=$$1
        v=$$(echo $$tag | grep -o "^[0-9]\+")
        echo $$v
    }

    function get_minor_version {
        local tag=$$1
        v=$$(echo $$tag | grep -o "^[0-9]\+\.[0-9]\+\.[0-9]\+" | grep -o "\.[0-9]\+\." | perl -pe 's/\.//g')
        echo $$v
    }

    function get_patch_version {
        local tag=$$1
        v=$$(echo $$tag | grep -o "^[0-9]\+\.[0-9]\+\.[0-9]\+" | grep -o "[0-9]\+\$$")
        echo $$v
    }

    function get_version_type {
        local tag=$$1
        local result

        validate_tag $$tag

        if [[ "$$tag" =~ [1-9]+\.0\.0 ]]; then
            result=major
        elif [[ "$$tag" =~ [1-9]+\.[1-9]+\.0 ]]; then
            result=minor
        else
            result=patch
        fi

        echo $$result
    }

    function bump_major_version {
        local current_tag=$$1
        local major=$$(get_major_version $$current_tag)

        echo $$(($$major+1)).0.0
    }

    function bump_minor_version {
        local current_tag=$$1
        local major=$$(get_major_version $$current_tag)
        local minor=$$(get_minor_version $$current_tag)

        echo $$major.$$((minor+1)).0
    }

    function bump_patch_version {
        local current_tag=$$1
        local major=$$(get_major_version $$current_tag)
        local minor=$$(get_minor_version $$current_tag)
        local patch=$$(get_patch_version $$current_tag)

        echo $$major.$$minor.$$((patch+1))
    }

    function create_release_candidate {
        local prod_tag=$$1
        local labels=$$2
        local RC

        validate_tag $$prod_tag || return $$?

        case $$labels in
            *version::external*)
                new_tag=$$(bump_major_version $$prod_tag)-rc
                RC=$$?
                ;;
            *version::internal*)
                new_tag=$$(bump_minor_version $$prod_tag)-rc
                RC=$$?
                ;;
            *version::bugfix*)
                new_tag=$$(bump_patch_version $$prod_tag)-rc
                RC=2  # signals we push straight to prod
                ;;
            *)
                echo "No valid version label found in $$labels" >&2
                return 1  # signals error
                ;;
        esac

        validate_tag $$new_tag || return $$?

        echo $$new_tag
        return $$RC
    }
